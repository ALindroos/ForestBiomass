{"cells":[{"cell_type":"markdown","metadata":{},"source":["Simple UI demo, extract data and performs inference for an area by given coordinates\n","Tested in Google colab to work with Google Earth Engine"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12803,"status":"ok","timestamp":1652261959546,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"rSrQxkWwN-TK","outputId":"d68d6fb3-375b-4dd6-89b6-4d7749701193"},"outputs":[],"source":["!pip install geopandas\n","import ee\n","import geopandas as gpd\n","import numpy as np\n","from shapely.ops import split\n","from shapely.geometry import MultiPolygon, Polygon, LineString\n","import threading\n","import concurrent.futures\n","import joblib\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29221,"status":"ok","timestamp":1652262066359,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"YTfPW79lOHaL","outputId":"dcc752c5-3e45-4d2e-dc55-d66a0abcbab4"},"outputs":[],"source":["ee.Authenticate()\n","ee.Initialize()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1652262068541,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"tUzmBskvQFWG"},"outputs":[],"source":["## extracting hila polygon\n","## splits the area given by coordinates to 16x16m areas.\n","# Due to projection issues, precision is not queranteed\n","# as orientation is differs between projections.\n","# should average over when using larger areas.\n","\n","def extract_hila(coords):\n","  poly = gpd.GeoDataFrame([Polygon(coords)], columns={\"geometry\"}, crs=\"EPSG:4326\")\n","  poly = poly.to_crs(epsg=2039)\n","  G = np.random.choice(poly.geometry.values)\n","  hilas = split_polygon(G,shape='square',thresh=0.5,side_length=16)\n","  \n","  res = gpd.GeoDataFrame(geometry=hilas, crs=\"EPSG:2039\")\n","  res = res.to_crs(epsg=4326)\n","  return res\n","\n","\n","def get_squares_from_rect(RectangularPolygon, side_length=0.0025):\n","    \"\"\"\n","    Divide a Rectangle (Shapely Polygon) into squares of equal area.\n","\n","    `side_length` : required side of square\n","\n","    \"\"\"\n","    rect_coords = np.array(RectangularPolygon.boundary.coords.xy)\n","    y_list = rect_coords[1]\n","    x_list = rect_coords[0]\n","    y1 = min(y_list)\n","    y2 = max(y_list)\n","    x1 = min(x_list)\n","    x2 = max(x_list)\n","    width = x2 - x1\n","    height = y2 - y1\n","\n","    xcells = int(np.round(width / side_length))\n","    ycells = int(np.round(height / side_length))\n","\n","    yindices = np.linspace(y1, y2, ycells + 1)\n","    xindices = np.linspace(x1, x2, xcells + 1)\n","    horizontal_splitters = [\n","        LineString([(x, yindices[0]), (x, yindices[-1])]) for x in xindices\n","    ]\n","    vertical_splitters = [\n","        LineString([(xindices[0], y), (xindices[-1], y)]) for y in yindices\n","    ]\n","    result = RectangularPolygon\n","    for splitter in vertical_splitters:\n","        result = MultiPolygon(split(result, splitter))\n","    for splitter in horizontal_splitters:\n","        result = MultiPolygon(split(result, splitter))\n","    square_polygons = list(result)\n","\n","    return square_polygons\n","\n","\n","def split_polygon(G, side_length=0.025, shape=\"square\", thresh=0.9):\n","    \"\"\"\n","    Using a rectangular envelope around `G`, creates a mesh of squares of required length.\n","    \n","    Removes non-intersecting polygons. \n","            \n","\n","    Args:\n","    \n","    - `thresh` : Range - [0,1]\n","\n","        This controls - the number of smaller polygons at the boundaries.\n","        \n","        A thresh == 1 will only create (or retain) smaller polygons that are \n","        completely enclosed (area of intersection=area of smaller polygon) \n","        by the original Geometry - `G`.\n","        \n","        A thresh == 0 will create (or retain) smaller polygons that \n","        have a non-zero intersection (area of intersection>0) with the\n","        original geometry - `G` \n","\n","    - `side_length` : Range - (0,infinity)\n","        side_length must be such that the resultant geometries are smaller \n","        than the original geometry - `G`, for a useful result.\n","\n","        side_length should be >0 (non-zero positive)\n","\n","    - `shape` : {square/rhombus}\n","        Desired shape of subset geometries. \n","\n","\n","    \"\"\"\n","    assert side_length>0, \"side_length must be a float>0\"\n","    Rectangle    = G.envelope\n","    squares      = get_squares_from_rect(Rectangle, side_length=side_length)\n","    SquareGeoDF  = gpd.GeoDataFrame(squares).rename(columns={0: \"geometry\"})\n","    Geoms        = SquareGeoDF[SquareGeoDF.intersects(G)].geometry.values\n","    if shape == \"square\":\n","        geoms = [g for g in Geoms if ((g.intersection(G)).area / g.area) >= thresh]\n","    return geoms"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":201,"status":"ok","timestamp":1652262073482,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"1dY4xxo_RJo5"},"outputs":[],"source":["## Sentinel 2 satelite data processing\n","# Recommembed settings for satellite image filtering\n","CLOUD_FILTER = 60\n","CLD_PRB_THRESH = 40\n","NIR_DRK_THRESH = 0.15\n","CLD_PRJ_DIST = 2\n","BUFFER = 100\n","\n","def get_s2_img(aoi, start_date='2021-07-01', end_date='2021-08-01'):    \n","    s2_sr_cld_col = get_s2_sr_cld_col(aoi, start_date, end_date)\n","    return (s2_sr_cld_col.map(add_cld_shdw_mask)\n","                .map(apply_cld_shdw_mask)\n","                .median()) \n","    \n","def get_s2_sr_cld_col(aoi, start_date, end_date):\n","    # Import and filter S2 SR.\n","    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n","        .filterBounds(aoi)\n","        .filterDate(start_date, end_date)\n","        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n","\n","    # Import and filter s2cloudless.\n","    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n","        .filterBounds(aoi)\n","        .filterDate(start_date, end_date))\n","\n","    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n","    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n","        'primary': s2_sr_col,\n","        'secondary': s2_cloudless_col,\n","        'condition': ee.Filter.equals(**{\n","            'leftField': 'system:index',\n","            'rightField': 'system:index'\n","        })\n","    }))\n","\n","def add_shadow_bands(img):\n","    # Identify water pixels from the SCL band.\n","    not_water = img.select('SCL').neq(6)\n","\n","    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n","    SR_BAND_SCALE = 1e4\n","    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n","\n","    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n","    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n","\n","    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n","    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n","        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n","        .select('distance')\n","        .mask()\n","        .rename('cloud_transform'))\n","\n","    # Identify the intersection of dark pixels with cloud shadow projection.\n","    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n","\n","    # Add dark pixels, cloud projection, and identified shadows as image bands.\n","    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n","\n","\n","def add_cloud_bands(img):\n","    # Get s2cloudless image, subset the probability band.\n","    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n","\n","    # Condition s2cloudless by the probability threshold value.\n","    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n","\n","    # Add the cloud probability layer and cloud mask as image bands.\n","    return img.addBands(ee.Image([cld_prb, is_cloud]))\n","\n","\n","def apply_cld_shdw_mask(img):\n","    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n","    not_cld_shdw = img.select('cloudmask').Not()\n","\n","    # Subset reflectancemethods bands and update their masks, return the result.\n","    return img.select('B.*').updateMask(not_cld_shdw)\n","\n","\n","def add_cld_shdw_mask(img):\n","    # Add cloud component bands.\n","    img_cloud = add_cloud_bands(img)\n","\n","    # Add cloud shadow component bands.\n","    img_cloud_shadow = add_shadow_bands(img_cloud)\n","\n","    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n","    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n","\n","    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n","    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n","    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n","        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n","        .rename('cloudmask'))\n","\n","    # Add the final cloud-shadow mask to the image.\n","    return img_cloud_shadow.addBands(is_cld_shdw)\n","\n","\n","#extract bands from sentinel data\n","def hila_bands(x, band):\n","  aoi = ee.Geometry.Polygon(x)\n","  img = get_s2_img(aoi)\n","\n","  mean_band = img.select(band).reduceRegion(**{\n","    \"reducer\": ee.Reducer.mean(),\n","    \"geometry\": aoi,\n","    \"scale\": 10,  # A nominal scale in meters of the projection to work in\n","  })\n","\n","  std_band = img.select(band).reduceRegion(**{\n","    \"reducer\": ee.Reducer.stdDev(),\n","    \"geometry\": aoi,\n","    \"scale\": 10,  # A nominal scale in meters of the projection to work in\n","  })\n","\n","  max_band = img.select(band).reduceRegion(**{\n","    \"reducer\": ee.Reducer.max(),\n","    \"geometry\": aoi,\n","    \"scale\": 10,  # A nominal scale in meters of the projection to work in\n","  })\n","\n","  min_band = img.select(band).reduceRegion(**{\n","    \"reducer\": ee.Reducer.min(),\n","    \"geometry\": aoi,\n","    \"scale\": 10,  # A nominal scale in meters of the projection to work in\n","  })\n","\n","  return [mean_band.getNumber(band), std_band.getNumber(band), max_band.getNumber(band), min_band.getNumber(band)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":209,"status":"ok","timestamp":1652262077581,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"pqZDpP4wRnra"},"outputs":[],"source":["## processing hila grids\n","#extract band values for the hila-grids\n","#Collect Numbers to List, evaluate once to save time in getInfo() calls\n","def extract_bands(coords, band):\n","  ln = len(coords)\n","  chunk = 500\n","  res = []\n","\n","  # due to user memory limit, need to work in 1K chunks of data\n","  for i in range(0, ln, chunk):\n","    lim = i+chunk\n","    if lim > ln:\n","      lim = ln\n","\n","    tmp = coords[i:lim].apply(lambda x: hila_bands(x, band))\n","    res.extend(ee.List([x for x in tmp]).getInfo())\n","\n","  return res\n","\n","def process_hila(df):\n","  bands = ['B2', 'B3', 'B4', 'B8']\n","\n","  with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n","    futures = [executor.submit(extract_bands, df['coords'], band) for band in bands]\n","\n","  for i, future in enumerate(futures):\n","    band = bands[i]\n","    df[[f'{band}_mean',f'{band}_std', f'{band}_max', f'{band}_min']] = future.result()\n","  \n","  return df\n","\n","def conv_Polygon(poly):\n","  x,y = poly.exterior.coords.xy\n","  coords = np.dstack((x,y)).tolist()\n","  #geo = ee.Geometry.Polygon(coords)\n","  #feature = ee.Feature(geo)\n","  return coords"]},{"cell_type":"markdown","metadata":{},"source":["Coordinates here decide the area, arbitrary Polygon shapes are technically supported.\n","The resolution is forced 16x16 meters from the Hila-data, so predictions on smaller areas, especially if not easily dividable by 16 can be inaccurate."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348719,"status":"ok","timestamp":1652262430456,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"7H8JOovBR1HK","outputId":"12b8112c-1d07-4c2e-8565-ee382dbadd50"},"outputs":[],"source":["coords = [[24.3218, 61.2715], \n","     [24.3218, 61.2627], \n","     [24.3405, 61.2627], \n","     [24.3405, 61.2715]]\n","\n","hila = extract_hila(coords)\n","hila['coords'] = hila['geometry'].map(conv_Polygon)\n","hila = process_hila(hila)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1652262439249,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"Rk6AuuhafzaJ"},"outputs":[],"source":["def set_index_variables(df):    \n","    df['ndvi'] = (df['B8_mean'] - df['B4_mean'])/(df['B8_mean'] + df['B4_mean'])\n","    df['gndvi'] = (df['B8_mean'] - df['B3_mean'])/(df['B8_mean'] + df['B3_mean'])\n","    df['evi'] = 2.5 * ((df['B8_mean'] - df['B4_mean'])/(df['B8_mean'] - 6*df['B4_mean'] - 7.5*df['B2_mean'] + 1))\n","    df['sr'] = df['B8_mean'] / df['B4_mean']\n","    df['msr'] = ((df['B8_mean'])/(df['B4_mean']-1)) / (np.sqrt((df['B8_mean'])/(df['B4_mean']))+1)\n","    df['savi'] = (1+1) * (df['B8_mean']-df['B4_mean'])/(df['B8_mean']+df['B4_mean'])\n","    df['ctvi'] = (df['ndvi']+0.5)/(abs(df['ndvi']+0.5)) * np.sqrt(abs(df['ndvi']+0.5))\n","    df['ttvi'] = np.sqrt(abs((df['B8_mean']-df['B4_mean'])/(df['B8_mean']+df['B4_mean']) + 0.5))\n","    df['rvi'] = df['B4_mean'] / df['B8_mean']\n","    df['nrvi'] = (df['rvi']-1)/(df['rvi']+1)\n","    df['ipvi'] = (df['B8_mean']) / (df['B8_mean']+df['B4_mean'])\n","    df['osavi'] = (df['B8_mean']-df['B4_mean']) / (df['B8_mean']+df['B4_mean']+0.16)\n","    df['tndvi'] = np.sqrt(df['ndvi']+0.5)\n","    df['grvi'] = (df['B3_mean']-df['B4_mean']) / (df['B3_mean']+df['B4_mean'])\n","    df['arvi'] = (df['B8_mean']-(2*df['B4_mean']-df['B2_mean']))/(df['B8_mean']+(2*df['B4_mean']-df['B2_mean']))\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12322,"status":"ok","timestamp":1652264660707,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"Rxhw7pBvhBb5","outputId":"a35188d0-0077-4aab-b9fa-653fb302bb06"},"outputs":[],"source":["rf = joblib.load('./rf-final.joblib')\n","rf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2076,"status":"ok","timestamp":1652265009038,"user":{"displayName":"Adiel Lindroos","userId":"00846395874327727580"},"user_tz":-180},"id":"9hhtBcDbhG8Q","outputId":"9066244e-62dc-4cd0-9a50-d8f82296ea71"},"outputs":[],"source":["selected_features = ['B8_max', 'grvi', 'B2_mean', 'B3_mean', 'B8_min', 'B4_std', 'B3_max', 'B8_mean',\n","                     'gndvi', 'B8_std', 'B2_max', 'B4_min', 'B2_min', 'B4_mean', 'B3_min', 'B2_std',\n","                     'B4_max', 'msr', 'ctvi', 'rvi', 'osavi', 'sr', 'ndvi', 'nrvi', 'ipvi', 'ttvi', \n","                     'savi', 'tndvi', 'evi', 'B3_std']\n","\n","X = hila[selected_features]\n","y_pred = rf.predict(X)\n","y_pred"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP/8gdqsFFBAWOEhJDW61hZ","collapsed_sections":[],"name":"hila_interface.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
